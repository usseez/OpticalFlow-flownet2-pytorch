"""compare the result of onnx and pth model overlay on the same image......"""
import os
import cv2
import numpy as np
import torch
import onnxruntime as ort
import matplotlib.pyplot as plt
import sys

from models import FlowNet2C
from networks.correlation_package import correlation as corr_mod
import argparse
from types import SimpleNamespace

CKPT_PATH = "./weights/251114/451_FlowNet2C_model_best.pth.tar"
# ONNX_PATH = "./weights/checkpoints_pseudo_fund/pwcnet_proxy_epoch_85.onnx"
ONNX_PATH = "./weights/251114/451_FlowNet2C.onnx"


DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"

IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

def make_parser():
    parser = argparse.ArgumentParser("Resnet onnx deploy")
    parser.add_argument(
        "-t", "--model_type", default="FlowNet2C", type=str, help="input model tpye of resnet model"
    )
    parser.add_argument(
        "--output_name", type=str, default="FlowNet2C.onnx", help="output name of models"
    )
    parser.add_argument(
        "-i", "--input", default="images", type=str, help="input node name of onnx model"
    )
    parser.add_argument(
        "-o", "--output", default="output", type=str, help="output node name of onnx model"
    )
    parser.add_argument(
        "--opset", default=13, type=int, help="onnx opset version"
    )
    parser.add_argument("--no-onnxsim", action="store_true", help="use onnxsim or not")
    parser.add_argument("-c", "--ckpt", default=None, type=str, help="ckpt path")
    
    
    return parser
# 1) optical flowë¥¼ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ê°„ë‹¨ ë²„ì „)
def flow_to_color(flow):
    """
    flow: (H, W, 2)
    """
    fx = flow[..., 0]
    fy = flow[..., 1]

    mag, ang = cv2.cartToPolar(fx, fy, angleInDegrees=False)
    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.float32)

    hsv[..., 0] = ang / (2 * np.pi)  # [0,1] ë²”ìœ„ hue
    hsv[..., 1] = 1.0
    if mag.max() > 1e-6:
        hsv[..., 2] = mag / (mag.max() + 1e-6)
    else:
        hsv[..., 2] = 0.0

    hsv_uint8 = (hsv * 255).astype(np.uint8)
    hsv_bgr = cv2.cvtColor(hsv_uint8, cv2.COLOR_HSV2BGR)
    rgb = cv2.cvtColor(hsv_bgr, cv2.COLOR_BGR2RGB)
    return rgb


# 2) ì´ë¯¸ì§€ ë‘ ì¥ì„ ì½ì–´ì„œ (H,W,3) ë‘ ê°œ â†’ (1,6,H,W) í…ì„œë¡œ ë§Œë“¤ê¸°
def load_image_pair_to_6ch_tensor(img1_path, img2_path, resize_hw=(384, 512)):
    # 1) ì´ë¯¸ì§€ ë¡œë“œ (BGR â†’ RGB)
    im1 = cv2.imread(img1_path)
    im2 = cv2.imread(img2_path)
    assert im1 is not None and im2 is not None, "ì´ë¯¸ì§€ ê²½ë¡œ ë‹¤ì‹œ í™•ì¸!"

    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)
    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)

    # 2) í•™ìŠµ ë•Œì™€ ë™ì¼í•œ Resize (H, W) = (384, 512)
    if resize_hw is not None:
        H, W = resize_hw
        im1 = cv2.resize(im1, (W, H), interpolation=cv2.INTER_LINEAR)
        im2 = cv2.resize(im2, (W, H), interpolation=cv2.INTER_LINEAR)

    # overlayìš©ìœ¼ë¡œëŠ” "ì •ê·œí™” ì•ˆ ëœ" RGB uint8 ì´ë¯¸ì§€ í•œ ì¥ ë³´ê´€
    base_img = im1.copy()   # (H, W, 3), uint8, RGB

    # 3) ToTensorì™€ ë™ì¼í•œ ë™ì‘: [0,255] â†’ [0,1], HWC â†’ CHW
    im1_f = im1.astype(np.float32) / 255.0   # (H,W,3)
    im2_f = im2.astype(np.float32) / 255.0

    im1_chw = np.transpose(im1_f, (2, 0, 1))  # (3,H,W)
    im2_chw = np.transpose(im2_f, (2, 0, 1))

    # 4) Normalize(mean, std) ì ìš© (ì±„ë„ë³„)
    mean = IMAGENET_MEAN[:, None, None]      # (3,1,1)
    std  = IMAGENET_STD[:, None, None]       # (3,1,1)

    im1_norm = (im1_chw - mean) / std
    im2_norm = (im2_chw - mean) / std

    # 5) concat â†’ (6,H,W), batch ì°¨ì› ì¶”ê°€ â†’ (1,6,H,W)
    im6 = np.concatenate([im1_norm, im2_norm], axis=0)  # (6,H,W)
    im6 = np.expand_dims(im6, axis=0)                   # (1,6,H,W)

    return im6.astype(np.float32), base_img


def run_pytorch_pwcnet(tensor_6ch):
    corr_mod.USE_ONNX_CORRELATION = True

    if args.model_type == 'FlowNet2C':
        flownet_args = SimpleNamespace(rgb_max=255.0, fp16=False)
        model = FlowNet2C(flownet_args)
    else:
        print('Unknown model type!')
        sys.exit(1)

    ckpt = torch.load(CKPT_PATH, map_location="cpu", weights_only=True)
    state = ckpt["state_dict"] if "state_dict" in ckpt else ckpt
    model.load_state_dict(state, strict=True)
    model.to(DEVICE).eval()

    x6 = torch.from_numpy(tensor_6ch).to(DEVICE).float()  # (B,6,H,W)

    # (B,6,H,W) -> (B,3,2,H,W)  (img1 RGB + img2 RGB ë¡œ catí•œ ê²½ìš° ê¸°ì¤€)
    if x6.ndim != 4 or x6.shape[1] != 6:
        raise ValueError(f"Expected (B,6,H,W), got {tuple(x6.shape)}")

    B, _, H, W = x6.shape
    x = x6.view(B, 2, 3, H, W).permute(0, 2, 1, 3, 4).contiguous()

    with torch.no_grad():
        out = model(x)

    flow = out[0] if isinstance(out, (list, tuple)) else out
    flow_np = flow[0].detach().cpu().numpy().transpose(1, 2, 0)  # (H,W,2)
    return flow_np



def run_onnx_pwcnet(tensor_6ch):
    """
    tensor_6ch: (1,6,H,W) numpy
    """
    sess = ort.InferenceSession(ONNX_PATH, providers=["CPUExecutionProvider"])  ##model íŒŒì¼(onnx) ì—´ê¸°

    # input / output ì´ë¦„ í™•ì¸
    input_name = sess.get_inputs()[0].name
    output_name = sess.get_outputs()[0].name



    x6 = tensor_6ch.astype(np.float32)  # (1,6,H,W)
    B, _, H, W = x6.shape
    
    x = x6.reshape(B, 2, 3, H, W).transpose(0, 2, 1, 3, 4).copy()
    
    outputs = sess.run([output_name], {input_name: x})
    flow = outputs[0]  # (1,2,H,W) ê°€ì •
    flow_np = np.transpose(flow[0], (1, 2, 0))  # (H,W,2)
    return flow_np


def compare_flows(flow_pth, flow_onnx):
    assert flow_pth.shape == flow_onnx.shape

    a = flow_pth.astype(np.float32)
    b = flow_onnx.astype(np.float32)

    # 1) ì ˆëŒ€ì ì¸ ì°¨ì´
    diff = a - b
    l2 = np.linalg.norm(diff.ravel())                     # L2 norm of diff
    mae = np.mean(np.abs(diff))                           # MAE
    max_abs = np.max(np.abs(diff))                        # max |diff|

    # 2) ìƒëŒ€ì ì¸ ì°¨ì´ (scale ê³ ë ¤)
    l2_ref  = np.linalg.norm(a.ravel())                   # ê¸°ì¤€: pth
    mae_ref = np.mean(np.abs(a)) + 1e-8

    rel_l2  = l2 / (l2_ref + 1e-8)                        # ìƒëŒ€ L2
    rel_mae = mae / mae_ref                               # ìƒëŒ€ MAE

    # 3) Pearson ìƒê´€ê³„ìˆ˜ (ì „ì²´ ê°’ì„ 1Dë¡œ í¼ì³ì„œ)
    a_flat = a.ravel()
    b_flat = b.ravel()
    corr = np.corrcoef(a_flat, b_flat)[0, 1]              # -1 ~ 1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ

    # 4) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë°©í–¥ì´ ë¹„ìŠ·í•œì§€)
    cos_sim = np.dot(a_flat, b_flat) / (
        np.linalg.norm(a_flat) * np.linalg.norm(b_flat) + 1e-8
    )                                                     # -1 ~ 1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ

    # 5) optical flow ì „ìš© ì§€í‘œ: Endpoint Error (EPE)
    #    ê° í”½ì…€ë§ˆë‹¤ flow ë²¡í„° (u,v)ì˜ ì°¨ì´ì˜ L2 norm
    vec_diff = np.linalg.norm(a - b, axis=-1)             # (H, W)
    epe_mean = np.mean(vec_diff)
    epe_max  = np.max(vec_diff)

    # ğŸ”¹ ì¼ì¹˜ìœ¨ (%): EPEê°€ tau ì´í•˜ì¸ í”½ì…€ ë¹„ìœ¨
    taus = [0.25, 0.5, 1.0, 2.0]

    agreements = {}
    for tau in taus:
        agree = (vec_diff <= tau).mean() * 100.0
        agreements[f"agree@{tau}"] = agree


    print(f"L2 diff           : {l2}")
    print(f"MAE               : {mae}")
    print(f"Max abs diff      : {max_abs}")
    print(f"Relative L2 diff  : {rel_l2}")
    print(f"Relative MAE      : {rel_mae}")
    print(f"Pearson corr      : {corr}")
    print(f"Cosine similarity : {cos_sim}")
    print(f"EPE mean          : {epe_mean}")
    print(f"EPE max           : {epe_max}")

    for tau in taus:
        print(f"Agreement @ EPE<={tau:4.2f} : {agreements[f'agree@{tau}']:6.2f}%")

    return {
        "L2 diff": l2,
        "MAE": mae,
        "Max abs diff": max_abs,
        "Relative L2 diff": rel_l2,
        "Relative MAE": rel_mae,
        "Pearson corr": corr,
        "Cosine similarity": cos_sim,
        "EPE mean": epe_mean,
        "EPE max": epe_max,
        "agreements": agreements,
    }


def overlay_flow_on_image(img, flow_color, alpha=0.6):
    # í˜¹ì‹œ grayscaleì´ë©´ ì»¬ëŸ¬ë¡œ ë³€í™˜
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    if len(flow_color.shape) == 2:
        flow_color = cv2.cvtColor(flow_color, cv2.COLOR_GRAY2BGR)

    # 1) í¬ê¸° ë§ì¶”ê¸°  (cv2.resizeëŠ” (width, height) ìˆœì„œ!)
    if img.shape[:2] != flow_color.shape[:2]:
        h, w = img.shape[:2]
        flow_color = cv2.resize(flow_color, (w, h), interpolation=cv2.INTER_LINEAR)

    # 2) dtype ë§ì¶”ê¸° (ë³´í†µ uint8)
    if img.dtype != flow_color.dtype:
        flow_color = flow_color.astype(img.dtype)

    # 3) ì˜¤ë²„ë ˆì´
    overlay = cv2.addWeighted(img, 1 - alpha, flow_color, alpha, 0)
    return overlay

#debug
def print_flow_stats(name, flow):
    print(f"[{name}] shape={flow.shape}")
    print(f"  min  : {flow.min():.4f}")
    print(f"  max  : {flow.max():.4f}")
    print(f"  mean : {flow.mean():.4f}")
    print(f"  std  : {flow.std():.4f}")

    

if __name__ == "__main__":

    args = make_parser().parse_args()
    # ì˜ˆì‹œ ì´ë¯¸ì§€ ê²½ë¡œ (ë„¤ ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)
    img1_path = "./Dataset/test/roll0_tilt-3_yaw-6_0043.png"
    img2_path = "./Dataset/test/roll0_tilt-3_yaw-6_0048.png"

    # 1) ì…ë ¥ ì¤€ë¹„
    input_6ch, base_img = load_image_pair_to_6ch_tensor(img1_path, img2_path)
    print("input shape:", input_6ch.shape)  # (1,6,H,W)

    # 2) PyTorch ëª¨ë¸ ì¶”ë¡ 
    flow_pth = run_pytorch_pwcnet(input_6ch)
    print("flow_pth shape:", flow_pth.shape)

    # 3) ONNX ëª¨ë¸ ì¶”ë¡ 
    flow_onnx = run_onnx_pwcnet(input_6ch)
    print("flow_onnx shape:", flow_onnx.shape)

    # 4) ìˆ˜ì¹˜ ë¹„êµ
    metrics = compare_flows(flow_pth, flow_onnx)






    # 5) ì»¬ëŸ¬ë¡œ ë§Œë“¤ê³  overlay
    color_pth = flow_to_color(flow_pth)      # RGB
    color_onnx = flow_to_color(flow_onnx)    # RGB

    overlay_pth = overlay_flow_on_image(base_img, color_pth, alpha=0.6)      # RGB
    overlay_onnx = overlay_flow_on_image(base_img, color_onnx, alpha=0.6)    # RGB

    # 6) OpenCVë¡œ íŒŒì¼ ì €ì¥ (BGR ë³€í™˜ í›„)
    save_dir = "./results_overlay"
    os.makedirs(save_dir, exist_ok=True)

    # OpenCVëŠ” BGRì´ë¯€ë¡œ RGB â†’ BGR ë³€í™˜
    overlay_pth_bgr = cv2.cvtColor(overlay_pth, cv2.COLOR_RGB2BGR)
    overlay_onnx_bgr = cv2.cvtColor(overlay_onnx, cv2.COLOR_RGB2BGR)
    color_pth_bgr = cv2.cvtColor(color_pth, cv2.COLOR_RGB2BGR)
    color_onnx_bgr = cv2.cvtColor(color_onnx, cv2.COLOR_RGB2BGR)

    # cv2.imwrite(os.path.join(save_dir, "overlay_pth.png"), overlay_pth_bgr)
    # cv2.imwrite(os.path.join(save_dir, "overlay_onnx.png"), overlay_onnx_bgr)
    # cv2.imwrite(os.path.join(save_dir, "flow_color_pth.png"), color_pth_bgr)
    # cv2.imwrite(os.path.join(save_dir, "flow_color_onnx.png"), color_onnx_bgr)

    # ==============================
    # 8) í•œ ì¥ì§œë¦¬ ë¦¬í¬íŠ¸ ì´ë¯¸ì§€ ë§Œë“¤ê¸°
    # ==============================
    # 4ì¥ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ê°™ì€ í¬ê¸°ë¼ê³  ê°€ì • (overlay í•¨ìˆ˜ì—ì„œ ë§ì¶°ì¤¬ìœ¼ë‹ˆê¹Œ)
    h, w, c = overlay_pth_bgr.shape

    # 2x2 ê·¸ë¦¬ë“œ í¬ê¸°
    grid_h = 2 * h
    grid_w = 2 * w

    # ì˜¤ë¥¸ìª½ ì—¬ë°± í­ (í•„ìš”í•˜ë©´ ì¡°ì ˆ)
    margin_w = 400

    # ì „ì²´ ìº”ë²„ìŠ¤ (ê²€ì • ë°°ê²½)
    canvas_h = grid_h
    canvas_w = grid_w + margin_w
    canvas = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)

    
    color_pth_bgr_big  = cv2.resize(color_pth_bgr,  (w, h), interpolation=cv2.INTER_LINEAR)
    color_onnx_bgr_big = cv2.resize(color_onnx_bgr, (w, h), interpolation=cv2.INTER_LINEAR)
    # ê·¸ë¦¬ë“œì— 4ì¥ ë°°ì¹˜
    # ì¢Œì¸¡ ìƒë‹¨
    canvas[0:h, 0:w, :] = overlay_pth_bgr
    # ìš°ì¸¡ ìƒë‹¨
    canvas[0:h, w:2*w, :] = overlay_onnx_bgr
    # ì¢Œì¸¡ í•˜ë‹¨
    canvas[h:2*h, 0:w, :] = color_onnx_bgr_big
    # ìš°ì¸¡ í•˜ë‹¨
    canvas[h:2*h, w:2*w, :] = color_onnx_bgr_big

    # ==============================
    # 9) ì˜¤ë¥¸ìª½ ì—¬ë°±ì— í…ìŠ¤íŠ¸ ì“°ê¸°
    # ==============================
    text_x = grid_w + 10      # ê·¸ë¦¬ë“œ ì˜¤ë¥¸ìª½ + 10px
    text_y = 30               # ì‹œì‘ ë†’ì´
    line_height = 35          # ì¤„ ê°„ê²©

    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.5
    thickness = 1
    color = (255, 255, 255)       # ì´ˆë¡ìƒ‰ (BGR)

    lines = [
        f"flow_pth shape : {flow_pth.shape}",
        f"flow_onnx shape: {flow_onnx.shape}",
        "",
        f"L2 diff           : {metrics['L2 diff']:.6f}",
        f"MAE               : {metrics['MAE']:.6f}",
        f"Max abs diff      : {metrics['Max abs diff']:.6f}",
        f"Relative L2 diff  : {metrics['Relative L2 diff']:.6f}",
        f"Relative MAE      : {metrics['Relative MAE']:.6f}",
        f"Pearson corr      : {metrics['Pearson corr']:.6f}",
        f"Cosine similarity : {metrics['Cosine similarity']:.6f}",
        f"EPE mean          : {metrics['EPE mean']:.6f}",
        f"EPE max           : {metrics['EPE max']:.6f}",
    ]

    for i, line in enumerate(lines):
        y = text_y + i * line_height
        cv2.putText(canvas, line, (text_x, y), font, font_scale, color, thickness, cv2.LINE_AA)

    # print(f"Saved results to: {os.path.abspath(save_dir)}")
    single_path = os.path.join(save_dir, "comparison_report.png")

    print_flow_stats("pth", flow_pth)
    print_flow_stats("onnx", flow_onnx)

    cv2.imwrite(single_path, canvas)
    print("Saved combined report image to:", os.path.abspath(single_path))